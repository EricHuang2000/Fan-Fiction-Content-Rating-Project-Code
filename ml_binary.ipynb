{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61ca6a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_bin = pd.read_csv(r'C:\\Users\\erich\\Desktop\\DS_project\\data\\data_30_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d37a392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               HTML_Content                                        TXT_Content\n",
      "0     Teen And Up Audiences  huckleberry finn stood front old wooden door m...\n",
      "1     Teen And Up Audiences  right huck trying figure every sort way could ...\n",
      "3     Teen And Up Audiences  air hot brow wet mind exhausted st petersburg ...\n",
      "5     Teen And Up Audiences  rope burned skin rubbing flesh raw shoved push...\n",
      "6     Teen And Up Audiences  tom sawyer liked consider hopeless romantic ot...\n",
      "...                     ...                                                ...\n",
      "6030                 Mature  sorry late robin blurted soon within earshot c...\n",
      "6036  Teen And Up Audiences  seen news pat asked robin chance hang coat mor...\n",
      "6037  Teen And Up Audiences  free next friday night murphy smiled phone rob...\n",
      "6038                 Mature  turned walked away wan na say come baby give w...\n",
      "6040                 Mature  heaven fact unlike earth pro con pro include t...\n",
      "\n",
      "[3055 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def data_binary(df):\n",
    "    \n",
    "    df = df[df['HTML_Content'].isin(['Teen And Up Audiences', 'Mature'])]\n",
    "    \n",
    "    df = df.dropna(subset=['TXT_Content'])\n",
    "\n",
    "    def clean_text(text):\n",
    "\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "        text = text.lower()\n",
    "        tokenized_text = word_tokenize(text)\n",
    "        cleaned_text = [lemmatizer.lemmatize(word) for word in tokenized_text if word not in set(stopwords.words('english'))]\n",
    "\n",
    "        return ' '.join(cleaned_text)\n",
    "\n",
    "    df['TXT_Content'] = df['TXT_Content'].apply(clean_text)\n",
    "\n",
    "    return df\n",
    "\n",
    "data_bin = data_binary(data_bin)\n",
    "print(data_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab4ca67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Naive Bayes\n",
      "Accuracy: 0.6596\n",
      "Recall: 0.0000\n",
      "F1-score: 0.0000\n",
      "----------------------------------------\n",
      "Classifier: Random Forest\n",
      "Accuracy: 0.6792\n",
      "Recall: 0.0865\n",
      "F1-score: 0.1552\n",
      "----------------------------------------\n",
      "Classifier: SVM\n",
      "Accuracy: 0.6809\n",
      "Recall: 0.1010\n",
      "F1-score: 0.1772\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(data_bin['TXT_Content'])\n",
    "y = data_bin['HTML_Content']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "classifiers = {\n",
    "    \"Naive Bayes\": MultinomialNB(alpha=0.5, fit_prior=True),\n",
    "    \"Random Forest\": RandomForestClassifier(max_depth=None, min_samples_split=5, n_estimators=400),\n",
    "    \"SVM\": SVC(C=1, gamma=1, kernel='rbf', probability=True) \n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"Classifier: {name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"Recall: {recall_score(y_test, y_pred, pos_label='Mature'):.4f}\")\n",
    "    print(f\"F1-score: {f1_score(y_test, y_pred, pos_label='Mature'):.4f}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a619ec30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6596\n",
      "Recall: 1.0000\n",
      "F1-score: 0.7949\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(data_bin['TXT_Content'])\n",
    "y = data_bin['HTML_Content']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = MultinomialNB(alpha=0.5, fit_prior=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, pos_label='Teen And Up Audiences'):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_test, y_pred, pos_label='Teen And Up Audiences'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80236c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
