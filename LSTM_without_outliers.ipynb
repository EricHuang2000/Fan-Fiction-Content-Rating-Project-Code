{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "869a2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_30_sentences = pd.read_csv(r'C:\\Users\\erich\\Desktop\\DS_project\\data\\cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2339150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               HTML_Content                                        TXT_Content\n",
      "0     Teen And Up Audiences  huckleberry finn stood front old wooden door m...\n",
      "1     Teen And Up Audiences  right huck trying figure every sort way could ...\n",
      "3     Teen And Up Audiences  air hot brow wet mind exhausted st petersburg ...\n",
      "5     Teen And Up Audiences  rope burned skin rubbing flesh raw shoved push...\n",
      "6     Teen And Up Audiences  tom sawyer liked consider hopeless romantic ot...\n",
      "...                     ...                                                ...\n",
      "5797                 Mature  sorry late robin blurted soon within earshot c...\n",
      "5803  Teen And Up Audiences  seen news pat asked robin chance hang coat mor...\n",
      "5804  Teen And Up Audiences  free next friday night murphy smiled phone rob...\n",
      "5805                 Mature  turned walked away wan na say come baby give w...\n",
      "5807                 Mature  heaven fact unlike earth pro con pro include t...\n",
      "\n",
      "[2953 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def data_binary(df):\n",
    "    \n",
    "    df = df[df['HTML_Content'].isin(['Teen And Up Audiences', 'Mature'])]\n",
    "    \n",
    "    df = df.dropna(subset=['TXT_Content'])\n",
    "\n",
    "    def clean_text(text):\n",
    "\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "        text = text.lower()\n",
    "        tokenized_text = word_tokenize(text)\n",
    "        cleaned_text = [lemmatizer.lemmatize(word) for word in tokenized_text if word not in set(stopwords.words('english'))]\n",
    "\n",
    "        return ' '.join(cleaned_text)\n",
    "\n",
    "    df['TXT_Content'] = df['TXT_Content'].apply(clean_text)\n",
    "\n",
    "    return df\n",
    "\n",
    "data_30_sentences = data_binary(data_30_sentences)\n",
    "print(data_30_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01934d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\AppData\\Local\\Temp\\ipykernel_23460\\460413102.py:34: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, TimeDistributed, Flatten, Attention\n",
    "from keras.models import Sequential\n",
    "from keras.metrics import Precision, Recall\n",
    "from keras.callbacks import EarlyStopping\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "# Pre-processing\n",
    "max_length = 300\n",
    "embedding_dim = 100\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data_30_sentences['TXT_Content'])\n",
    "sequences = tokenizer.texts_to_sequences(data_30_sentences['TXT_Content'])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "labels = to_categorical(np.asarray(LabelEncoder().fit_transform(data_30_sentences['HTML_Content'])))\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Word Embedding\n",
    "glove_input_file = 'C:\\\\Users\\\\erich\\\\Desktop\\\\DS_project\\\\code\\\\glove.6B\\\\glove.6B.100d.txt'\n",
    "word2vec_output_file = 'C:\\\\Users\\\\erich\\\\Desktop\\\\DS_project\\\\code\\\\glove.6B\\\\glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec:\n",
    "        embedding_matrix[i] = word2vec[word] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff7979f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "15/15 [==============================] - 233s 16s/step - loss: 0.6622 - accuracy: 0.6368 - precision: 0.6368 - recall: 0.6368 - val_loss: 0.6708 - val_accuracy: 0.6216 - val_precision: 0.6216 - val_recall: 0.6216\n",
      "Epoch 2/3\n",
      "15/15 [==============================] - 263s 18s/step - loss: 0.6563 - accuracy: 0.6406 - precision: 0.6406 - recall: 0.6406 - val_loss: 0.6825 - val_accuracy: 0.6216 - val_precision: 0.6216 - val_recall: 0.6216\n",
      "Epoch 3/3\n",
      "15/15 [==============================] - 286s 19s/step - loss: 0.6532 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - val_loss: 0.6683 - val_accuracy: 0.6216 - val_precision: 0.6216 - val_recall: 0.6216\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 297s 20s/step - loss: 0.6506 - accuracy: 0.6421 - precision: 0.6421 - recall: 0.6421 - val_loss: 0.6722 - val_accuracy: 0.6258 - val_precision: 0.6258 - val_recall: 0.6258\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 309s 21s/step - loss: 0.6466 - accuracy: 0.6427 - precision: 0.6427 - recall: 0.6427 - val_loss: 0.6661 - val_accuracy: 0.6152 - val_precision: 0.6152 - val_recall: 0.6152\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 315s 21s/step - loss: 0.6388 - accuracy: 0.6464 - precision: 0.6464 - recall: 0.6464 - val_loss: 0.6839 - val_accuracy: 0.6237 - val_precision: 0.6237 - val_recall: 0.6237\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 322s 22s/step - loss: 0.6424 - accuracy: 0.6411 - precision: 0.6411 - recall: 0.6411 - val_loss: 0.6648 - val_accuracy: 0.6237 - val_precision: 0.6237 - val_recall: 0.6237\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 328s 22s/step - loss: 0.6499 - accuracy: 0.6406 - precision: 0.6406 - recall: 0.6406 - val_loss: 0.6645 - val_accuracy: 0.6216 - val_precision: 0.6216 - val_recall: 0.6216\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 332s 22s/step - loss: 0.6352 - accuracy: 0.6490 - precision: 0.6490 - recall: 0.6490 - val_loss: 0.6768 - val_accuracy: 0.5983 - val_precision: 0.5983 - val_recall: 0.5983\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 336s 23s/step - loss: 0.6413 - accuracy: 0.6506 - precision: 0.6506 - recall: 0.6506 - val_loss: 0.6668 - val_accuracy: 0.6110 - val_precision: 0.6110 - val_recall: 0.6110\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 342s 23s/step - loss: 0.6230 - accuracy: 0.6559 - precision: 0.6559 - recall: 0.6559 - val_loss: 0.6921 - val_accuracy: 0.6025 - val_precision: 0.6025 - val_recall: 0.6025\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 332s 22s/step - loss: 0.6213 - accuracy: 0.6760 - precision: 0.6760 - recall: 0.6760 - val_loss: 0.6889 - val_accuracy: 0.6110 - val_precision: 0.6110 - val_recall: 0.6110\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 399s 27s/step - loss: 0.6192 - accuracy: 0.6670 - precision: 0.6670 - recall: 0.6670 - val_loss: 0.6949 - val_accuracy: 0.6025 - val_precision: 0.6025 - val_recall: 0.6025\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(word_index) + 1, embedding_dim, weights=[embedding_matrix], \n",
    "                    input_length=max_length, trainable=False))\n",
    "model.add(LSTM(256, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(LSTM(128, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(labels[0]), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy', Precision(), Recall()])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history_3 = model.fit(X_train, y_train, \n",
    "                    batch_size=128, epochs=3, \n",
    "                    validation_split=0.2, \n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "model.reset_states()\n",
    "\n",
    "history_10 = model.fit(X_train, y_train, \n",
    "                    batch_size=128, epochs=10, \n",
    "                    validation_split=0.2, \n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb81ca88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
