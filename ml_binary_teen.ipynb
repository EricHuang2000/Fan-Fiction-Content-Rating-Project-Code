{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bca3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_bin = pd.read_csv(r'C:\\Users\\erich\\Desktop\\DS_project\\data\\data_30_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eabc35b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               HTML_Content                                        TXT_Content\n",
      "0     Teen And Up Audiences  huckleberry finn stood front old wooden door m...\n",
      "1     Teen And Up Audiences  right huck trying figure every sort way could ...\n",
      "2                    Others  three buried mother christmas eve thing huck c...\n",
      "3     Teen And Up Audiences  air hot brow wet mind exhausted st petersburg ...\n",
      "4                    Others  episode genre al chaos chaos space time vortex...\n",
      "...                     ...                                                ...\n",
      "6036  Teen And Up Audiences  seen news pat asked robin chance hang coat mor...\n",
      "6037  Teen And Up Audiences  free next friday night murphy smiled phone rob...\n",
      "6038                 Others  turned walked away wan na say come baby give w...\n",
      "6039                 Others  perfect word tended apply liberally one often ...\n",
      "6040                 Others  heaven fact unlike earth pro con pro include t...\n",
      "\n",
      "[6005 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_bin_teen(df):\n",
    "    df = df[df['HTML_Content'].isin(['Explicit', 'General Audiences', 'Mature', 'Not Rated', 'Teen And Up Audiences'])]\n",
    "\n",
    "    df = df.dropna(subset=['TXT_Content'])\n",
    "\n",
    "    def clean_text(text):\n",
    "\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "        text = text.lower()\n",
    "        tokenized_text = word_tokenize(text)\n",
    "        cleaned_text = [lemmatizer.lemmatize(word) for word in tokenized_text if word not in set(stopwords.words('english'))]\n",
    "\n",
    "        return ' '.join(cleaned_text)\n",
    "\n",
    "    df['TXT_Content'] = df['TXT_Content'].apply(clean_text)\n",
    "    \n",
    "    df['HTML_Content'] = df['HTML_Content'].apply(lambda x: 'Others' if x != 'Teen And Up Audiences' else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "data_bin = clean_bin_teen(data_bin)\n",
    "print(data_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ae5bf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7019\n",
      "Recall: 0.0138\n",
      "F1-score: 0.0272\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(data_bin['TXT_Content'])\n",
    "y = data_bin['HTML_Content']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = MultinomialNB(alpha=0.5, fit_prior=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred, pos_label='Teen And Up Audiences'):.4f}\")\n",
    "print(f\"F1-score: {f1_score(y_test, y_pred, pos_label='Teen And Up Audiences'):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e738a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
