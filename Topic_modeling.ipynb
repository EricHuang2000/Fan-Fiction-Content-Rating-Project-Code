{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b382fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_30_sentences = pd.read_csv(r'C:\\Users\\erich\\Desktop\\DS_project\\data\\data_30_sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b221edf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\AppData\\Local\\Temp\\ipykernel_29068\\3495218422.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['TXT_Content'] = df['TXT_Content'].apply(clean_text)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english')).union({\"one\",\"would\",\"could\",\"time\",\"back\",\"still\",\"even\",\"hand\",\"know\",\"eye\",\"day\",\"said\",\"say\"})\n",
    "\n",
    "def clean_data(df):\n",
    "    df = df.dropna(subset=['TXT_Content'])\n",
    "\n",
    "    def clean_text(text):\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "        text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "        text = text.lower()\n",
    "        tokenized_text = word_tokenize(text)\n",
    "        cleaned_text = [lemmatizer.lemmatize(word) for word in tokenized_text if word not in stop_words]\n",
    "        return ' '.join(cleaned_text)\n",
    "\n",
    "    df['TXT_Content'] = df['TXT_Content'].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "data_30_sentences = clean_data(data_30_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "344f0ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\erich\\anaconda3\\lib\\site-packages (1.9.1.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\erich\\anaconda3\\lib\\site-packages (from wordcloud) (9.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\erich\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a789d7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in c:\\users\\erich\\anaconda3\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: numexpr in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: funcy in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.0)\n",
      "Requirement already satisfied: gensim in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.3.1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pyLDAvis) (61.2.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from pandas>=2.0.0->pyLDAvis) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (5.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\erich\\anaconda3\\lib\\site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\erich\\anaconda3\\lib\\site-packages (from packaging->numexpr->pyLDAvis) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38584fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import CoherenceModel\n",
    "import os\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "tokenized_texts = [word_tokenize(text) for text in data_30_sentences['TXT_Content'].values]\n",
    "\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "doc_term_matrix = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "\n",
    "num_topics = 20\n",
    "num_words = 20\n",
    "\n",
    "lda = LdaModel(doc_term_matrix, num_topics=num_topics, id2word=dictionary, passes=50)\n",
    "\n",
    "lda_display = pyLDAvis.gensim_models.prepare(lda, doc_term_matrix, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)\n",
    "\n",
    "topics = []\n",
    "\n",
    "for text in doc_term_matrix:\n",
    "\n",
    "    topic_distribution = lda.get_document_topics(text)\n",
    "    topic_distribution = sorted(topic_distribution, key=lambda x: x[1], reverse=True)\n",
    "    top_topics = [topic[0] for topic in topic_distribution[:10]]\n",
    "\n",
    "    topics.append(top_topics)\n",
    "\n",
    "data_30_sentences['Topic'] = topics\n",
    "\n",
    "data_30_sentences.to_csv(r'C:\\Users\\erich\\Desktop\\DS_project\\data\\30_topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de9f3593",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_display = pyLDAvis.gensim_models.prepare(lda, doc_term_matrix, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)\n",
    "pyLDAvis.save_html(lda_display, 'C:\\\\Users\\\\erich\\\\Desktop\\\\DS_project\\\\data\\\\lda.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f55e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
